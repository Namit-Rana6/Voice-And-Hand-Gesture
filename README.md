# HandsFreeX

> **Accessible Digital Control System ‚Äî Empowering hands-free interaction through voice commands and head gestures.**

---

## üöÄ Overview

**HandsFreeX** is a hands-free digital control platform that allows users to operate a computer using only **voice commands** and **head gestures**.

Built to bridge the accessibility gap, it empowers individuals with **motor impairments**, **upper limb disabilities**, **temporary injuries**, or **fatigue** to navigate, communicate, and interact ‚Äî independently and confidently.

---

## üéØ Features

### üîä Voice Control
- Open apps and websites (Google, YouTube, Stack Overflow, etc.)
- Play YouTube songs via voice
- Send WhatsApp messages
- Send emails
- Fetch weather and news updates
- Set alarms and reminders
- Adjust system volume and brightness
- Scroll, navigate, and automate system tasks
- Engage in AI-based conversations (using OpenAI GPT)
- Translate text between languages (e.g., English to Hindi, French, etc.)
- Fun utilities: Toss coin, roll dice, tell jokes, fun facts
- Hands-free mouse navigation via voice

### üé• Head Gesture Control
- Move mouse pointer using simple head movements
- Perform clicks without any physical device
- Built using only a webcam ‚Äî no external hardware needed
- Optimized for smooth, fatigue-free control

---

## üìπ Demo

**Prototype Videos:**
- Voice Mode: Command-driven task execution
- Gesture Mode: Cursor control with head movements
- [Add YouTube or Drive Link Here if needed]

---

## üõ†Ô∏è Tech Stack

- **Python 3.9+**
- **SpeechRecognition** ‚Äî Voice input processing
- **PyAudio** ‚Äî Microphone handling
- **pyttsx3** ‚Äî Text-to-Speech (TTS) output
- **PyAutoGUI** ‚Äî Mouse, scroll, and keyboard automation
- **OpenCV** ‚Äî Real-time head tracking
- **TensorFlow Lite** ‚Äî Lightweight models for gesture interpretation
- **Requests** ‚Äî API requests for weather and news
- **PyWhatKit** ‚Äî WhatsApp messaging, YouTube control
- **Googletrans** ‚Äî Translation services
- **OpenAI GPT API** ‚Äî AI chat assistant

---

## üåü Why HandsFreeX?

- **Minimal Setup:** Just a webcam and a microphone.
- **Real-Time Performance:** No lag, no bulky hardware.
- **Designed for Dignity:** Not just access, but independence and freedom.
- **Expandable Foundation:** Ready for future modules like predictive navigation and personalized learning.

---

## üîÆ Future Roadmap

- üîó Merge voice and gesture input seamlessly for hybrid control
- üß† Add adaptive learning for custom gestures and voice styles
- üéØ Improve personalization (predictive shortcuts, recommendations)
- ü¶Æ Accessibility upgrades (blind-friendly audio navigation)

---

## üí¨ Setup Instructions (Optional)

> _[Add if you want]_  
> _Clone the repository and install required Python dependencies listed in `requirements.txt`._
> ```
> pip install -r requirements.txt
> python voice_assistant.py
> ```

---

## ü§ù Team

- [Your Name 1] - [Role/Contribution]
- [Your Name 2] - [Role/Contribution]

*Built with ‚ù§Ô∏è at [Hackathon Name] 2024.*

---

## ‚ú® HandsFreeX: **Control the Web. Without Hands.**

---
