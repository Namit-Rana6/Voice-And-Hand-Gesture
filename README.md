# HandsFreeX

> **Accessible Digital Control System — Empowering hands-free interaction through voice commands and head gestures.**

---

## 🚀 Overview

**HandsFreeX** is a hands-free digital control platform that allows users to operate a computer using only **voice commands** and **head gestures**.

Built to bridge the accessibility gap, it empowers individuals with **motor impairments**, **upper limb disabilities**, **temporary injuries**, or **fatigue** to navigate, communicate, and interact — independently and confidently.

---

## 🎯 Features

### 🔊 Voice Control
- Open apps and websites (Google, YouTube, Stack Overflow, etc.)
- Play YouTube songs via voice
- Send WhatsApp messages
- Send emails
- Fetch weather and news updates
- Set alarms and reminders
- Adjust system volume and brightness
- Scroll, navigate, and automate system tasks
- Engage in AI-based conversations (using OpenAI GPT)
- Translate text between languages (e.g., English to Hindi, French, etc.)
- Fun utilities: Toss coin, roll dice, tell jokes, fun facts
- Hands-free mouse navigation via voice

### 🎥 Head Gesture Control
- Move mouse pointer using simple head movements
- Perform clicks without any physical device
- Built using only a webcam — no external hardware needed
- Optimized for smooth, fatigue-free control

---

## 📹 Demo

**Prototype Videos:**
- Voice Mode: Command-driven task execution
- Gesture Mode: Cursor control with head movements
- [Add YouTube or Drive Link Here if needed]

---

## 🛠️ Tech Stack

- **Python 3.9+**
- **SpeechRecognition** — Voice input processing
- **PyAudio** — Microphone handling
- **pyttsx3** — Text-to-Speech (TTS) output
- **PyAutoGUI** — Mouse, scroll, and keyboard automation
- **OpenCV** — Real-time head tracking
- **TensorFlow Lite** — Lightweight models for gesture interpretation
- **Requests** — API requests for weather and news
- **PyWhatKit** — WhatsApp messaging, YouTube control
- **Googletrans** — Translation services
- **OpenAI GPT API** — AI chat assistant

---

## 🌟 Why HandsFreeX?

- **Minimal Setup:** Just a webcam and a microphone.
- **Real-Time Performance:** No lag, no bulky hardware.
- **Designed for Dignity:** Not just access, but independence and freedom.
- **Expandable Foundation:** Ready for future modules like predictive navigation and personalized learning.

---

## 🔮 Future Roadmap

- 🔗 Merge voice and gesture input seamlessly for hybrid control
- 🧠 Add adaptive learning for custom gestures and voice styles
- 🎯 Improve personalization (predictive shortcuts, recommendations)
- 🦮 Accessibility upgrades (blind-friendly audio navigation)


---

## 🤝 Team - OINK

- Namit Rana - 
- Khushboo Kataria - 

*Built with ❤️ at Geekverse IEEE GGSIPU 2024.*

---

## ✨ HandsFreeX: **Control the Web. Without Hands.**

---
